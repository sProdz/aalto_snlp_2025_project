# Configuration for Goodreads Quote Clustering Pipeline.
# !Note that the whole processing using the full dataset with CPU multithreading will likely take a long time (Macbook air using 8 cores +45 minutes).
# TSNE is memory bound so running with GPU is likely not going to make it faster

# --- File Paths (Relative to project root when running main.py from root) ---
raw_data_file: "data/quotes/quotes.csv"
intermediate_dir: "data/BOW_intermediate" # Changed path relative to project root
preprocessed_file_suffix: "_preprocessed.parquet" # Suffix for files saved in intermediate_dir
# bow_results_suffix: "_bow_tsne.parquet" # Commented out as only TF-IDF is needed
tfidf_results_suffix: "data/BOW/data_tfidf_tsne.parquet" # Final results path relative to project root

# --- Processing Parameters ---
n_clusters: 10
n_svd_components: 100
random_state: 42 # For reproducibility in sampling/t-SNE

# --- Vectorizer Parameters (Optional: Add more specific ones if needed) ---
# These apply to both BoW and TF-IDF unless overridden
vectorizer_min_df: 0.001
vectorizer_max_df: 0.95

# --- Analysis Parameters ---
n_samples_per_cluster: 3
# --- Display Options (Less common to configure via YAML, but possible) ---
# display_max_colwidth: 100
# display_max_rows: 100

