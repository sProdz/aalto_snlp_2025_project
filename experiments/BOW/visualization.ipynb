{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from experiment.yaml\n",
      "--- Configuration Relevant for Visualization ---\n",
      "TF-IDF Results File: intermediate_data/data_tfidf_tsne.parquet\n",
      "N Clusters: 10\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "# --- Load Configuration from YAML ---\n",
    "# We only need file paths and cluster info from the config\n",
    "CONFIG_FILE = 'experiment.yaml'\n",
    "try:\n",
    "    with open(CONFIG_FILE, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"Loaded configuration from {CONFIG_FILE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Configuration file '{CONFIG_FILE}' not found.\")\n",
    "    # Define fallback defaults if needed (adjust if necessary)\n",
    "    config = {\n",
    "        'intermediate_dir': 'intermediate_data',\n",
    "        'tfidf_results_suffix': '_tfidf_tsne.parquet',\n",
    "        'n_clusters': 10,\n",
    "        'random_state': 42,\n",
    "        'n_samples_per_cluster': 3\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Error loading configuration from {CONFIG_FILE}: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Configuration Values ---\n",
    "INTERMEDIATE_DIR = config['intermediate_dir']\n",
    "TFIDF_RESULTS_FILE = os.path.join(INTERMEDIATE_DIR, f\"data{config['tfidf_results_suffix']}\")\n",
    "N_CLUSTERS = config['n_clusters']\n",
    "RANDOM_STATE = config.get('random_state', 42)\n",
    "N_SAMPLES_PER_CLUSTER = config['n_samples_per_cluster']\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_colwidth', 150) # Show more quote text\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"--- Configuration Relevant for Visualization ---\")\n",
    "print(f\"TF-IDF Results File: {TFIDF_RESULTS_FILE}\")\n",
    "print(f\"N Clusters: {N_CLUSTERS}\")\n",
    "print(\"-\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Visualize TF-IDF Clusters using t-SNE ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_final\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtsne_tfidf_1\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_final.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtsne_tfidf_2\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_final.columns:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating TF-IDF t-SNE plot...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m12\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Visualize TF-IDF Clusters using t-SNE ---\n",
    "\n",
    "if df_final is not None and 'tsne_tfidf_1' in df_final.columns and 'tsne_tfidf_2' in df_final.columns:\n",
    "    print(\"Generating TF-IDF t-SNE plot...\")\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne_tfidf_1\", y=\"tsne_tfidf_2\",\n",
    "        hue=\"tfidf_cluster\",\n",
    "        palette=sns.color_palette(\"hsv\", N_CLUSTERS), # Use N_CLUSTERS from config\n",
    "        data=df_final,\n",
    "        legend=\"full\",\n",
    "        alpha=0.3\n",
    "    )\n",
    "    plt.title(f'TF-IDF t-SNE Projection (k={N_CLUSTERS})')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend(title='TF-IDF Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping TF-IDF t-SNE plot: Data not loaded or t-SNE columns missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sample Quotes per TF-IDF Cluster ---\n",
    "\n",
    "if df_final is not None and 'tfidf_cluster' in df_final.columns:\n",
    "    print(f\"\\n--- Sampled Quotes per TF-IDF Cluster (k={N_CLUSTERS}) ---\")\n",
    "    n_samples_per_cluster = N_SAMPLES_PER_CLUSTER # Use value from config\n",
    "\n",
    "    # Ensure cluster IDs are integers if they are not already\n",
    "    if not pd.api.types.is_integer_dtype(df_final['tfidf_cluster']):\n",
    "         # Attempt conversion, handle potential errors if conversion fails\n",
    "         try:\n",
    "             df_final['tfidf_cluster'] = df_final['tfidf_cluster'].astype(int)\n",
    "         except ValueError:\n",
    "             print(\"Warning: Could not convert 'tfidf_cluster' column to integer type. Skipping sampling.\")\n",
    "             df_final = None # Prevent further processing\n",
    "\n",
    "    if df_final is not None:\n",
    "         # Check if tfidf_cluster column exists after potential removal due to conversion error\n",
    "         if 'tfidf_cluster' in df_final.columns:\n",
    "             # Sort unique cluster IDs numerically before iterating\n",
    "             unique_clusters = sorted(df_final['tfidf_cluster'].unique())\n",
    "             for cluster_id in unique_clusters:\n",
    "                 print(f\"\\n--- Cluster {cluster_id} Samples (TF-IDF) ---\")\n",
    "                 cluster_df = df_final[df_final['tfidf_cluster'] == cluster_id]\n",
    "                 # Ensure we don't try to sample more than available\n",
    "                 n_to_sample = min(n_samples_per_cluster, len(cluster_df))\n",
    "\n",
    "                 if n_to_sample > 0:\n",
    "                     cluster_samples = cluster_df.sample(\n",
    "                         n=n_to_sample,\n",
    "                         random_state=RANDOM_STATE # Use random state from config\n",
    "                     )\n",
    "                     # Display relevant columns - adjust 'quote' if needed\n",
    "                     for index, row in cluster_samples.iterrows():\n",
    "                          # Check if 'quote' column exists\n",
    "                          if 'quote' in row:\n",
    "                              print(f\"  Quote {index}: {row['quote']}\")\n",
    "                          else:\n",
    "                              print(f\"  Quote {index}: ('quote' column missing)\")\n",
    "\n",
    "                 else:\n",
    "                     print(\"  No quotes found for this cluster.\")\n",
    "                 print(\"-\" * 30)\n",
    "         else:\n",
    "              print(\"Skipping quote sampling: 'tfidf_cluster' column processing failed.\")\n",
    "\n",
    "else:\n",
    "     print(\"Skipping quote sampling: Data not loaded or 'tfidf_cluster' column missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "from bow import TextPreprocessor # Need the class definition to load the object\n",
    "\n",
    "# Define file paths (should match paths used for saving in main.py)\n",
    "VECTORIZER_FILE = os.path.join(INTERMEDIATE_DIR, 'tfidf_vectorizer.joblib')\n",
    "PREPROCESSOR_FILE = os.path.join(INTERMEDIATE_DIR, 'text_preprocessor.joblib')\n",
    "\n",
    "# --- Load the Preprocessor and Fitted Vectorizer ---\n",
    "try:\n",
    "    preprocessor = joblib.load(PREPROCESSOR_FILE)\n",
    "    vectorizer = joblib.load(VECTORIZER_FILE)\n",
    "    print(\"Loaded preprocessor and TF-IDF vectorizer.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not load preprocessor ('{PREPROCESSOR_FILE}') or vectorizer ('{VECTORIZER_FILE}').\")\n",
    "    print(\"Please ensure the main pipeline (main.py) has been run successfully to generate these files.\")\n",
    "    # Set objects to None to prevent errors in the next step\n",
    "    preprocessor = None\n",
    "    vectorizer = None\n",
    "\n",
    "# --- Define and Embed Your Query ---\n",
    "if preprocessor and vectorizer:\n",
    "    # Example Query:\n",
    "    raw_query = \"The meaning of life and the universe\"\n",
    "    print(f\"\\nRaw Query: '{raw_query}'\")\n",
    "\n",
    "    # 1. Preprocess the query using the loaded preprocessor\n",
    "    #    The preprocessor's transform method likely expects a list/Series\n",
    "    processed_query = preprocessor.transform([raw_query])[0]\n",
    "    print(f\"Processed Query: '{processed_query}'\")\n",
    "\n",
    "    # 2. Transform the processed query using the loaded vectorizer's `transform` method\n",
    "    #    IMPORTANT: Use `.transform()`, NOT `.fit_transform()`.\n",
    "    #    We want to use the existing vocabulary and IDF weights, not re-learn them.\n",
    "    query_vector = vectorizer.transform([processed_query])\n",
    "\n",
    "    print(f\"\\nQuery TF-IDF Vector (Shape: {query_vector.shape}):\")\n",
    "    # This is a sparse matrix, showing (row, column_index) -> value\n",
    "    print(query_vector)\n",
    "\n",
    "    # You can convert to a dense array if needed, but it might be large\n",
    "    # query_vector_dense = query_vector.toarray()\n",
    "    # print(\"\\nQuery TF-IDF Vector (Dense):\")\n",
    "    # print(query_vector_dense)\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping query embedding because preprocessor or vectorizer failed to load.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
